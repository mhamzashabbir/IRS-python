{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 IRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. The core purpose of this assignment is to give you the flavor of IRS. You need to follow some steps listed below and in the end, you'll be able to build your own small IRS. So, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"This is my book\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f1.png?raw=true)\n",
    "![\"This is my pen\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f2.png?raw=true)\n",
    "![\"This is book is intersting\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have intialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n",
    "file_list = []             # file_list to store the list of file names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code starts here   \n",
    "# Traverse directories and store files into dictionary\n",
    "for root, dirs, files in os.walk(\".\"):   # Traverse all files in the current directory and its subdirectories\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".txt\"):   # Only consider text files\n",
    "            file_count += 1\n",
    "            filepath = os.path.join(root, filename)  # Get file path\n",
    "            file_list.append(filename)   # Add filename to file_list\n",
    "            with open(filepath, \"r\") as f:           # Open file in read mode\n",
    "                words = f.read().lower().split()           # Read file contents and split into words\n",
    "                for word in words:                  # Loop over each word in the file\n",
    "                    if word not in files_dict:      # If the word is not already in the dictionary\n",
    "                        files_dict[word] = {filename: 1}   # Add the word to the dictionary with a dictionary of filenames containing it and their count\n",
    "                    elif filename not in files_dict[word]:   \n",
    "                        files_dict[word][filename] = 1    # Add filename to the dictionary for the word with count 1\n",
    "                    else:\n",
    "                        files_dict[word][filename] += 1   # Increment the count of the word in the filename in the dictionary\n",
    "#Your code ends here       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Number  of files\\n\", file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'this': {'f1.txt': 1, 'f2.txt': 1}, 'is': {'f1.txt': 1, 'f2.txt': 1, 'f3.txt': 1}, 'my': {'f1.txt': 1, 'f2.txt': 1, 'f3.txt': 1}, 'book': {'f1.txt': 1, 'f3.txt': 1}, 'pen': {'f2.txt': 1}, 'intersting': {'f3.txt': 1}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to print all the unique words in every file and store them in a set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique words in every file\n",
      " {'book', 'pen', 'is', 'intersting', 'my', 'this'}\n",
      "\n",
      "count of files     3\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "unique_word_set = set(files_dict.keys())   # Get unique words from files_dict\n",
    "\n",
    "\n",
    "print(\"\\nUnique words in every file\\n\", unique_word_set)    # Print set of unique words\n",
    "print(\"\\ncount of files    \", file_count)  # Print files count\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "# Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Term Document Matrix\n",
      "\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Dictionary of Unique Words:\n",
      " {'book': 0, 'intersting': 1, 'is': 2, 'my': 3, 'pen': 4, 'this': 5}\n",
      "\n",
      "Dictionary of Files:\n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "# Create Term Document Matrix\n",
    "term_doc_matrix = []\n",
    "word_index_dict = {}\n",
    "file_index_dict = {}\n",
    "\n",
    "# Loop over each unique word in the vocabulary and assign an index to each word\n",
    "for i, word in enumerate(sorted(unique_word_set)):\n",
    "    word_index_dict[word] = i\n",
    "\n",
    "# Loop over each file in the corpus and assign an index to each file\n",
    "for i, filename in enumerate(sorted(file_list)):\n",
    "    file_index_dict[filename] = i\n",
    "\n",
    "# Loop over each file in the corpus and create a row for each file in the term document matrix\n",
    "for i in range(len(file_list)):\n",
    "    row = [0] * len(unique_word_set)\n",
    "    term_doc_matrix.append(row)\n",
    "\n",
    "# Print the Term Document Matrix, Dictionary of Unique Words, and Dictionary of Files\n",
    "print(\"\\nTerm Document Matrix\\n\")\n",
    "for sublist in term_doc_matrix:\n",
    "    print(sublist)\n",
    "print(\"\\nDictionary of Unique Words:\\n\", word_index_dict)\n",
    "print(\"\\nDictionary of Files:\\n\", file_index_dict)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "# If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "# Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary of Unique Words:\n",
      " {'book': 0, 'intersting': 1, 'is': 2, 'my': 3, 'pen': 4, 'this': 5}\n",
      "\n",
      "Term Document Matrix\n",
      "[1, 0, 1, 1, 0, 1]\n",
      "[0, 0, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here \n",
    "# Fill the term document matrix\n",
    "for i, filename in enumerate(sorted(file_list)): # Loop over each file in the corpus and assign an index to each file\n",
    "    with open(filename, 'r') as file: # Open the file in read mode\n",
    "        file_words = file.read().lower().split() # Read the contents of the file and split the words into a list\n",
    "        for word in file_words: # Loop over each word in the list of file words\n",
    "            if word in unique_word_set: # Check if the word is in the unique word set\n",
    "                term_doc_matrix[i][word_index_dict[word]] = 1 # If the word is in the unique word set, mark the corresponding cell in the term document matrix as 1\n",
    "\n",
    "# Print the Term Document Matrix, Unique Vocabulary Dictionary, and File Index Dictionary\n",
    "print(\"\\nDictionary of Unique Words:\\n\", word_index_dict)\n",
    "print(\"\\nTerm Document Matrix\")\n",
    "for sublist in term_doc_matrix:\n",
    "    print(sublist)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o4.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colVector initially\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "\n",
    "colVector = [[0] for i in range(len(unique_word_set))]  # create a column vector of zeros with the same length as unique_word_set\n",
    "\n",
    "print(\"colVector initially\")  # print a message to indicate the initial state of colVector\n",
    "for sublist in colVector: # iterate over each sublist in colVector and print it\n",
    "    print(sublist)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o5.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write something for searching  very intersting \n"
     ]
    }
   ],
   "source": [
    "query = input(\"\\nWrite something for searching  \").lower()\n",
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exixts then increment the count of that word in word dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "colVector after query\n",
      "\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "\n",
    "for word in query.split(): # Split the query into words and loop over each word\n",
    "    if word in unique_word_set:  # Check if the word is in the set of unique words\n",
    "        colVector[word_index_dict[word]][0] += 1      # If the word exists, increment the count of that word in the column vector\n",
    "\n",
    "print(\"\\ncolVector after query\\n\") # Print the column vector after query\n",
    "for sublist in colVector: # iterate over each sublist in colVector and print it\n",
    "    print(sublist)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o6.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultant vector:\n",
      " [[0]\n",
      " [0]\n",
      " [1]]\n",
      "Max value in resultant vector: [1]\n",
      "Index of max value in resultant vector: 2\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "resultant_vector = np.dot(term_doc_matrix, colVector)  # Calculate the dot product of term_doc_matrix and colVector\n",
    "print(\"Resultant vector:\\n\", resultant_vector)  # Print the resultant vector\n",
    "max_index = np.argmax(resultant_vector)  # Get the index of the maximum value in the resultant vector\n",
    "print(\"Max value in resultant vector:\", resultant_vector[max_index])  # Print the maximum value in the resultant vector\n",
    "print(\"Index of max value in resultant vector:\", max_index)  # Print the index of the maximum value in the resultant vector\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o7.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File with maximum value in resultant vector: f3.txt\n",
      "\n",
      "My book is intersting\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "\n",
    "max_index = np.argmax(resultant_vector) # Find the index of the file with the maximum value in the resultant vector\n",
    "max_file_name = file_list[max_index] # Get the filename for the file with the maximum value\n",
    "print(f\"\\nFile with maximum value in resultant vector: {max_file_name}\\n\") # Print the filename for the file with the maximum value\n",
    "with open(max_file_name, 'r') as file: # Open and read the file with the maximum value\n",
    "    print(file.read()) # Print the contents of the file\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
